"""
é¡¹ç›®æœç´¢å™¨

æœ¬æ¨¡å—å®ç°äº†æ ¸å¿ƒçš„é¡¹ç›®æœç´¢å’Œç­›é€‰é€»è¾‘ï¼Œåè°ƒæ‰€æœ‰ç»„ä»¶å®Œæˆå®Œæ•´çš„å·¥ä½œæµç¨‹ã€‚
"""

import time
from datetime import datetime
from typing import Any, Dict, List, Optional

from .cache_manager import CacheManager
from .csv_exporter import CSVExporter
from .exceptions import GitHubAPIError
from .github_client import GitHubAPIClient
from .php_analyzer import PHPAnalyzer
from .rate_limit_handler import RateLimitHandler
from .search_result import SearchResult
from .semgrep_analyzer import SemgrepAnalyzer


class ProjectSearcher:
    """é¡¹ç›®æœç´¢å™¨ï¼Œåè°ƒæ‰€æœ‰ç»„ä»¶å®Œæˆé¡¹ç›®æœç´¢å’Œç­›é€‰"""

    def __init__(
        self,
        github_token: str,
        cache_manager: Optional[CacheManager] = None,
        rate_limit_handler: Optional[RateLimitHandler] = None,
        semgrep_analyzer: Optional[SemgrepAnalyzer] = None,
        php_analyzer: Optional[PHPAnalyzer] = None,
        csv_exporter: Optional[CSVExporter] = None,
    ) -> None:
        """
        åˆå§‹åŒ–é¡¹ç›®æœç´¢å™¨

        Args:
            github_token: GitHub APIè®¿é—®ä»¤ç‰Œ
            cache_manager: ç¼“å­˜ç®¡ç†å™¨
            rate_limit_handler: é€Ÿç‡é™åˆ¶å¤„ç†å™¨
            semgrep_analyzer: Semgrepåˆ†æå™¨
            php_analyzer: PHPåˆ†æå™¨
            csv_exporter: CSVå¯¼å‡ºå™¨
        """
        # åˆå§‹åŒ–ç»„ä»¶
        self.cache_manager = cache_manager or CacheManager()
        self.rate_limit_handler = rate_limit_handler or RateLimitHandler()
        self.semgrep_analyzer = semgrep_analyzer or SemgrepAnalyzer()
        self.php_analyzer = php_analyzer or PHPAnalyzer(self.semgrep_analyzer)
        self.csv_exporter = csv_exporter or CSVExporter()

        # åˆå§‹åŒ–GitHubå®¢æˆ·ç«¯
        self.github_client = GitHubAPIClient(
            github_token, self.cache_manager, self.rate_limit_handler
        )

        # æœç´¢ç»Ÿè®¡
        self.search_stats = {
            "total_searched": 0,
            "qualified_projects": 0,
            "rejected_projects": 0,
            "error_projects": 0,
            "start_time": None,
            "end_time": None,
        }

    def search_projects(
        self,
        search_queries: List[str],
        max_projects: int = 100,
        export_csv: bool = True,
        include_unqualified: bool = False,
    ) -> List[SearchResult]:
        """
        æœç´¢å¹¶ç­›é€‰PHPé¡¹ç›®

        Args:
            search_queries: æœç´¢æŸ¥è¯¢åˆ—è¡¨
            max_projects: æœ€å¤§é¡¹ç›®æ•°é‡
            export_csv: æ˜¯å¦å¯¼å‡ºCSVæ–‡ä»¶
            include_unqualified: æ˜¯å¦åŒ…å«ä¸ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨

        Raises:
            GitHubAPIError: GitHub APIè¯·æ±‚å¤±è´¥
            AnalysisError: é¡¹ç›®åˆ†æå¤±è´¥
        """
        self.search_stats["start_time"] = datetime.now()

        try:
            all_results: List[SearchResult] = []

            # 1. æœç´¢é¡¹ç›®
            for query in search_queries:
                print(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")
                search_results = self._search_github_projects(query, max_projects)
                all_results.extend(search_results)

            # 2. å»é‡
            unique_results = self._deduplicate_results(all_results)

            # 3. åº”ç”¨ç­›é€‰é€»è¾‘
            print(f"ğŸ“Š å¼€å§‹åˆ†æ {len(unique_results)} ä¸ªé¡¹ç›®...")
            filtered_results = self.apply_filtering_logic(unique_results)

            # 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_search_stats(filtered_results)

            # 5. å¯¼å‡ºCSVï¼ˆå¦‚æœéœ€è¦ï¼‰
            if export_csv:
                self._export_results(filtered_results, include_unqualified)

            self.search_stats["end_time"] = datetime.now()
            self._print_search_summary()

            return filtered_results

        except Exception as e:
            self.search_stats["end_time"] = datetime.now()
            raise GitHubAPIError(f"Project search failed: {e}") from e

    def apply_filtering_logic(self, results: List[SearchResult]) -> List[SearchResult]:
        """
        åº”ç”¨ä¸¥æ ¼çš„ç­›é€‰é€»è¾‘

        Args:
            results: åŸå§‹æœç´¢ç»“æœåˆ—è¡¨

        Returns:
            ç­›é€‰åçš„ç»“æœåˆ—è¡¨

        Raises:
            AnalysisError: é¡¹ç›®åˆ†æå¤±è´¥
        """
        filtered_results: List[SearchResult] = []

        for i, result in enumerate(results, 1):
            try:
                print(f"ğŸ”¬ åˆ†æé¡¹ç›® {i}/{len(results)}: {result.project_name}")

                # è·å–é¡¹ç›®æ–‡ä»¶å†…å®¹
                file_contents = self._get_project_files(result)

                if not file_contents:
                    print("   âŒ æœªæ‰¾åˆ°PHPæ–‡ä»¶")
                    result.add_metadata("analysis_error", "No PHP files found")
                    continue

                # åˆ†æé¡¹ç›®
                analysis_results = self.php_analyzer.analyze_multiple_files(
                    file_contents
                )

                # åˆå¹¶åˆ†æç»“æœ
                combined_analysis = self._combine_analysis_results(analysis_results)

                # æ›´æ–°ç»“æœ
                result.update_analysis_result(combined_analysis)

                # åº”ç”¨ç­›é€‰è§„åˆ™
                if self._meets_criteria(result):
                    filtered_results.append(result)
                    print(f"   âœ… ç¬¦åˆæ¡ä»¶: {result.detection_type}")
                else:
                    print(f"   âŒ ä¸ç¬¦åˆæ¡ä»¶: {result.rejection_reason}")

                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                time.sleep(0.5)

            except Exception as e:
                print(f"   âš ï¸ åˆ†æå¤±è´¥: {e}")
                result.add_metadata("analysis_error", str(e))
                self.search_stats["error_projects"] += 1

        return filtered_results

    def _search_github_projects(
        self, query: str, max_projects: int
    ) -> List[SearchResult]:
        """
        æœç´¢GitHubé¡¹ç›®

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_projects: æœ€å¤§é¡¹ç›®æ•°é‡

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨

        Raises:
            GitHubAPIError: GitHub APIè¯·æ±‚å¤±è´¥
        """
        try:
            # æœç´¢ä»£ç 
            search_results = self.github_client.search_code_content(
                query, language="PHP", per_page=min(max_projects, 100)
            )

            results: List[SearchResult] = []

            for item in search_results:
                try:
                    # è·å–ä»“åº“ä¿¡æ¯
                    repo_info = self._get_repository_info(item)

                    # åˆ›å»ºSearchResult
                    result = SearchResult.from_search_item(item, repo_info)
                    results.append(result)

                except Exception as e:
                    print(f"   âš ï¸ è·å–ä»“åº“ä¿¡æ¯å¤±è´¥: {e}")
                    continue

            return results

        except Exception as e:
            raise GitHubAPIError(f"GitHub search failed: {e}") from e

    def _get_repository_info(self, search_item: Dict[str, Any]) -> Dict[str, Any]:
        """
        è·å–ä»“åº“è¯¦ç»†ä¿¡æ¯

        Args:
            search_item: æœç´¢é¡¹

        Returns:
            ä»“åº“ä¿¡æ¯

        Raises:
            GitHubAPIError: APIè¯·æ±‚å¤±è´¥
        """
        repository = search_item.get("repository", {})
        owner = repository.get("owner", {}).get("login", "")
        repo_name = repository.get("name", "")

        if not owner or not repo_name:
            raise GitHubAPIError("Invalid repository information")

        return self.github_client.get_repository_info(owner, repo_name)

    def _get_project_files(self, result: SearchResult) -> Dict[str, str]:
        """
        è·å–é¡¹ç›®çš„PHPæ–‡ä»¶å†…å®¹

        Args:
            result: æœç´¢ç»“æœ

        Returns:
            æ–‡ä»¶è·¯å¾„åˆ°å†…å®¹çš„æ˜ å°„

        Raises:
            GitHubAPIError: APIè¯·æ±‚å¤±è´¥
        """
        try:
            # è·å–ä»“åº“æ–‡ä»¶åˆ—è¡¨
            contents = self.github_client.get_repository_contents(
                result.owner, result.repo_name
            )

            file_contents: Dict[str, str] = {}

            for item in contents:
                if item.get("type") == "file" and item.get("name", "").endswith(".php"):
                    try:
                        file_path = item.get("path", "")
                        content = self.github_client.get_file_content(
                            result.owner, result.repo_name, file_path
                        )
                        file_contents[file_path] = content

                        # é™åˆ¶æ–‡ä»¶æ•°é‡é¿å…è¿‡å¤šè¯·æ±‚
                        if len(file_contents) >= 10:
                            break

                    except Exception as e:
                        print(f"   âš ï¸ è·å–æ–‡ä»¶å¤±è´¥ {item.get('name', '')}: {e}")
                        continue

            return file_contents

        except Exception as e:
            raise GitHubAPIError(f"Failed to get project files: {e}") from e

    def _combine_analysis_results(
        self, analysis_results: Dict[str, Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åˆå¹¶å¤šä¸ªæ–‡ä»¶çš„åˆ†æç»“æœ

        Args:
            analysis_results: æ–‡ä»¶åˆ†æç»“æœ

        Returns:
            åˆå¹¶åçš„åˆ†æç»“æœ
        """
        combined = {
            "has_superglobal": False,
            "has_dynamic_functions": False,
            "has_dynamic_includes": False,
            "superglobal_usage": [],
            "dynamic_function_usage": [],
            "dynamic_include_usage": [],
            "analysis_summary": {},
            "timestamp": datetime.now().isoformat(),
        }

        for _file_path, result in analysis_results.items():
            # åˆå¹¶ä½¿ç”¨æƒ…å†µ
            combined["superglobal_usage"].extend(result.get("superglobal_usage", []))
            combined["dynamic_function_usage"].extend(
                result.get("dynamic_function_usage", [])
            )
            combined["dynamic_include_usage"].extend(
                result.get("dynamic_include_usage", [])
            )

            # åˆå¹¶æ ‡å¿—
            combined["has_superglobal"] = combined["has_superglobal"] or result.get(
                "has_superglobal", False
            )
            combined["has_dynamic_functions"] = combined[
                "has_dynamic_functions"
            ] or result.get("has_dynamic_functions", False)
            combined["has_dynamic_includes"] = combined[
                "has_dynamic_includes"
            ] or result.get("has_dynamic_includes", False)

        # ç”Ÿæˆåˆ†ææ‘˜è¦
        combined["analysis_summary"] = self._generate_combined_summary(combined)

        return combined

    def _generate_combined_summary(self, combined: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆå¹¶åçš„åˆ†ææ‘˜è¦

        Args:
            combined: åˆå¹¶çš„åˆ†æç»“æœ

        Returns:
            åˆ†ææ‘˜è¦
        """
        # 1. æ£€æŸ¥SuperGlobalä½¿ç”¨
        if not combined["has_superglobal"]:
            return {
                "status": "rejected",
                "reason": "No SuperGlobal usage found",
                "priority": 0,
            }

        # 2. æ£€æŸ¥ä¸»è¦åŠ¨æ€å‡½æ•°
        if combined["has_dynamic_functions"]:
            return {
                "status": "accepted",
                "reason": "Dynamic functions detected",
                "priority": 1,
                "detection_type": "primary_functions",
            }

        # 3. æ£€æŸ¥fallbackåŠ¨æ€includes
        if combined["has_dynamic_includes"]:
            return {
                "status": "accepted",
                "reason": "Dynamic includes detected",
                "priority": 2,
                "detection_type": "fallback_includes",
            }

        # 4. éƒ½ä¸ç¬¦åˆ
        return {
            "status": "rejected",
            "reason": "No dynamic functions or includes found",
            "priority": 0,
        }

    def _meets_criteria(self, result: SearchResult) -> bool:
        """
        æ£€æŸ¥é¡¹ç›®æ˜¯å¦ç¬¦åˆç­›é€‰æ ‡å‡†

        Args:
            result: æœç´¢ç»“æœ

        Returns:
            æ˜¯å¦ç¬¦åˆæ ‡å‡†
        """
        return result.is_qualified

    def _deduplicate_results(self, results: List[SearchResult]) -> List[SearchResult]:
        """
        å»é‡æœç´¢ç»“æœ

        Args:
            results: åŸå§‹ç»“æœåˆ—è¡¨

        Returns:
            å»é‡åçš„ç»“æœåˆ—è¡¨
        """
        seen = set()
        unique_results: List[SearchResult] = []

        for result in results:
            project_key = f"{result.owner}/{result.repo_name}"
            if project_key not in seen:
                seen.add(project_key)
                unique_results.append(result)

        return unique_results

    def _update_search_stats(self, results: List[SearchResult]) -> None:
        """
        æ›´æ–°æœç´¢ç»Ÿè®¡ä¿¡æ¯

        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
        """
        self.search_stats["total_searched"] = len(results)
        self.search_stats["qualified_projects"] = sum(
            1 for r in results if r.is_qualified
        )
        self.search_stats["rejected_projects"] = (
            self.search_stats["total_searched"]
            - self.search_stats["qualified_projects"]
        )

    def _export_results(
        self, results: List[SearchResult], include_unqualified: bool
    ) -> None:
        """
        å¯¼å‡ºç»“æœåˆ°CSV

        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            include_unqualified: æ˜¯å¦åŒ…å«ä¸ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®
        """
        try:
            # å¯¼å‡ºåŸºæœ¬ç»“æœ
            csv_path = self.csv_exporter.export_results(
                results, include_unqualified=include_unqualified
            )
            print(f"ğŸ“„ ç»“æœå·²å¯¼å‡ºåˆ°: {csv_path}")

            # å¯¼å‡ºæ‘˜è¦
            summary_path = self.csv_exporter.export_summary(results)
            print(f"ğŸ“Š æ‘˜è¦å·²å¯¼å‡ºåˆ°: {summary_path}")

            # å¯¼å‡ºè¯¦ç»†ç»“æœ
            detailed_path = self.csv_exporter.export_detailed_results(results)
            print(f"ğŸ“‹ è¯¦ç»†ç»“æœå·²å¯¼å‡ºåˆ°: {detailed_path}")

        except Exception as e:
            print(f"âš ï¸ å¯¼å‡ºå¤±è´¥: {e}")

    def _print_search_summary(self) -> None:
        """æ‰“å°æœç´¢æ‘˜è¦"""
        stats = self.search_stats
        duration = (
            stats["end_time"] - stats["start_time"]
            if stats["start_time"] and stats["end_time"]
            else None
        )

        print("\n" + "=" * 50)
        print("ğŸ” æœç´¢æ‘˜è¦")
        print("=" * 50)
        print(f"æ€»æœç´¢é¡¹ç›®æ•°: {stats['total_searched']}")
        print(f"ç¬¦åˆæ¡ä»¶é¡¹ç›®: {stats['qualified_projects']}")
        print(f"ä¸ç¬¦åˆæ¡ä»¶é¡¹ç›®: {stats['rejected_projects']}")
        print(f"åˆ†æé”™è¯¯é¡¹ç›®: {stats['error_projects']}")
        if duration:
            print(f"æ€»è€—æ—¶: {duration.total_seconds():.2f} ç§’")
        print("=" * 50)

    def get_search_statistics(self) -> Dict[str, Any]:
        """
        è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return self.search_stats.copy()

    def close(self) -> None:
        """å…³é—­æ‰€æœ‰èµ„æº"""
        self.github_client.close()
        self.cache_manager.cleanup_expired()
